{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9T_jM9lAWWFd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import six\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgTP6HyHWf4S"
   },
   "outputs": [],
   "source": [
    "IMAGE_ORDERING = 'channels_last'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ci-EMPuoXh9V"
   },
   "outputs": [],
   "source": [
    "# models/model_utils.py\n",
    "def get_segmentation_model( input , output ):\n",
    "\n",
    "\timg_input = input\n",
    "\to = output\n",
    "\n",
    "\to_shape = Model(img_input , o ).output_shape\n",
    "\ti_shape = Model(img_input , o ).input_shape\n",
    "\n",
    "\tif IMAGE_ORDERING == 'channels_first':\n",
    "\t\toutput_height = o_shape[2]\n",
    "\t\toutput_width = o_shape[3]\n",
    "\t\tinput_height = i_shape[2]\n",
    "\t\tinput_width = i_shape[3]\n",
    "\t\tn_classes = o_shape[1]\n",
    "\t\to = (Reshape((  -1  , output_height*output_width   )))(o)\n",
    "\t\to = (Permute((2, 1)))(o)\n",
    "\telif IMAGE_ORDERING == 'channels_last':\n",
    "\t\toutput_height = o_shape[1]\n",
    "\t\toutput_width = o_shape[2]\n",
    "\t\tinput_height = i_shape[1]\n",
    "\t\tinput_width = i_shape[2]\n",
    "\t\tn_classes = o_shape[3]\n",
    "\t\to = (Reshape((   output_height*output_width , -1    )))(o)\n",
    "\n",
    "\to = (Activation('softmax'))(o)\n",
    "\tmodel = Model( img_input , o )\n",
    "\tmodel.output_width = output_width\n",
    "\tmodel.output_height = output_height\n",
    "\tmodel.n_classes = n_classes\n",
    "\tmodel.input_height = input_height\n",
    "\tmodel.input_width = input_width\n",
    "\tmodel.model_name = \"\"\n",
    "\n",
    "\tmodel.train = MethodType( train , model )\n",
    "\tmodel.predict_segmentation = MethodType( predict , model )\n",
    "\t#model.predict_multiple = MethodType( predict_multiple , model )\n",
    "\t#model.evaluate_segmentation = MethodType( evaluate , model )\n",
    "\n",
    "\n",
    "\treturn model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIYDTjRrbBrA"
   },
   "outputs": [],
   "source": [
    "def image_segmentation_generator( images_path , segs_path ,  batch_size,  n_classes , input_height , input_width , output_height , output_width  , do_augment=False ):\n",
    "\t\n",
    "\n",
    "\timg_seg_pairs = get_pairs_from_paths( images_path , segs_path )\n",
    "\trandom.shuffle( img_seg_pairs )\n",
    "\tzipped = itertools.cycle( img_seg_pairs  )\n",
    "\n",
    "\twhile True:\n",
    "\t\tX = []\n",
    "\t\tY = []\n",
    "\t\tfor _ in range( batch_size) :\n",
    "\t\t\tim , seg = next(zipped) \n",
    "\n",
    "\t\t\tim = cv2.imread(im , 1 )\n",
    "\t\t\tseg = cv2.imread(seg , 1 )\n",
    "\n",
    "\t\t\tif do_augment:\n",
    "\t\t\t\timg , seg[:,:,0] = augment_seg( img , seg[:,:,0] )\n",
    "\n",
    "\t\t\tX.append( get_image_arr(im , input_width , input_height ,odering=IMAGE_ORDERING )  )\n",
    "\t\t\tY.append( get_segmentation_arr( seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "\t\tyield np.array(X) , np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rh9ty4XDZRlJ"
   },
   "outputs": [],
   "source": [
    "def train( model  , \n",
    "\t\ttrain_images  , \n",
    "\t\ttrain_annotations , \n",
    "\t\tinput_height=None , \n",
    "\t\tinput_width=None , \n",
    "\t\tn_classes=None,\n",
    "\t\tverify_dataset=True,\n",
    "\t\tcheckpoints_path=None , \n",
    "\t\tepochs = 5,\n",
    "\t\tbatch_size = 2,\n",
    "\t\tvalidate=False , \n",
    "\t\tval_images=None , \n",
    "\t\tval_annotations=None ,\n",
    "\t\tval_batch_size=2 , \n",
    "\t\tauto_resume_checkpoint=False ,\n",
    "\t\tload_weights=None ,\n",
    "\t\tsteps_per_epoch=512,\n",
    "\t\toptimizer_name='adadelta' \n",
    "\t):\n",
    "\n",
    "\n",
    "\tif  isinstance(model, six.string_types) : # check if user gives model name insteead of the model object\n",
    "\t\t# create the model from the name\n",
    "\t\tassert ( not n_classes is None ) , \"Please provide the n_classes\"\n",
    "\t\tif (not input_height is None ) and ( not input_width is None):\n",
    "\t\t\tmodel = model_from_name[ model ](  n_classes , input_height=input_height , input_width=input_width )\n",
    "\t\telse:\n",
    "\t\t\tmodel = model_from_name[ model ](  n_classes )\n",
    "\n",
    "\tn_classes = model.n_classes\n",
    "\tinput_height = model.input_height\n",
    "\tinput_width = model.input_width\n",
    "\toutput_height = model.output_height\n",
    "\toutput_width = model.output_width\n",
    "\n",
    "\n",
    "\tif validate:\n",
    "\t\tassert not (  val_images is None ) \n",
    "\t\tassert not (  val_annotations is None ) \n",
    "\n",
    "\tif not optimizer_name is None:\n",
    "\t\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\toptimizer= optimizer_name ,\n",
    "\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "\tif not checkpoints_path is None:\n",
    "\t\topen( checkpoints_path+\"_config.json\" , \"w\" ).write( json.dumps( {\n",
    "\t\t\t\"model_class\" : model.model_name ,\n",
    "\t\t\t\"n_classes\" : n_classes ,\n",
    "\t\t\t\"input_height\" : input_height ,\n",
    "\t\t\t\"input_width\" : input_width ,\n",
    "\t\t\t\"output_height\" : output_height ,\n",
    "\t\t\t\"output_width\" : output_width \n",
    "\t\t}))\n",
    "\n",
    "\tif ( not (load_weights is None )) and  len( load_weights ) > 0:\n",
    "\t\tprint(\"Loading weights from \" , load_weights )\n",
    "\t\tmodel.load_weights(load_weights)\n",
    "\n",
    "\tif auto_resume_checkpoint and ( not checkpoints_path is None ):\n",
    "\t\tlatest_checkpoint = find_latest_checkpoint( checkpoints_path )\n",
    "\t\tif not latest_checkpoint is None:\n",
    "\t\t\tprint(\"Loading the weights from latest checkpoint \"  ,latest_checkpoint )\n",
    "\t\t\tmodel.load_weights( latest_checkpoint )\n",
    "\n",
    "\n",
    "\tif verify_dataset:\n",
    "\t\tprint(\"Verifying train dataset\")\n",
    "\t\tverify_segmentation_dataset( train_images , train_annotations , n_classes )\n",
    "\t\tif validate:\n",
    "\t\t\tprint(\"Verifying val dataset\")\n",
    "\t\t\tverify_segmentation_dataset( val_images , val_annotations , n_classes )\n",
    "\n",
    "\n",
    "\ttrain_gen = image_segmentation_generator( train_images , train_annotations ,  batch_size,  n_classes , input_height , input_width , output_height , output_width   )\n",
    "\n",
    "\n",
    "\tif validate:\n",
    "\t\tval_gen  = image_segmentation_generator( val_images , val_annotations ,  val_batch_size,  n_classes , input_height , input_width , output_height , output_width   )\n",
    "\n",
    "\n",
    "\tif not validate:\n",
    "\t\tfor ep in range( epochs ):\n",
    "\t\t\tprint(\"Starting Epoch \" , ep )\n",
    "\t\t\tmodel.fit_generator( train_gen , steps_per_epoch  , epochs=1 )\n",
    "\t\t\tif not checkpoints_path is None:\n",
    "\t\t\t\tmodel.save_weights( checkpoints_path + \".\" + str( ep ) )\n",
    "\t\t\t\tprint(\"saved \" , checkpoints_path + \".model.\" + str( ep ) )\n",
    "\t\t\tprint(\"Finished Epoch\" , ep )\n",
    "\telse:\n",
    "\t\tfor ep in range( epochs ):\n",
    "\t\t\tprint(\"Starting Epoch \" , ep )\n",
    "\t\t\tmodel.fit_generator( train_gen , steps_per_epoch  , validation_data=val_gen , validation_steps=200 ,  epochs=1 )\n",
    "\t\t\tif not checkpoints_path is None:\n",
    "\t\t\t\tmodel.save_weights( checkpoints_path + \".\" + str( ep )  )\n",
    "\t\t\t\tprint(\"saved \" , checkpoints_path + \".model.\" + str( ep ) )\n",
    "\t\t\tprint(\"Finished Epoch\" , ep )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SiI5sU5ZdQP"
   },
   "outputs": [],
   "source": [
    "def predict( model=None , inp=None , out_fname=None , checkpoints_path=None    ):\n",
    "\n",
    "\tif model is None and ( not checkpoints_path is None ):\n",
    "\t\tmodel = model_from_checkpoint_path(checkpoints_path)\n",
    "\n",
    "\tassert ( not inp is None )\n",
    "\tassert( (type(inp) is np.ndarray ) or  isinstance( inp , six.string_types)  ) , \"Inupt should be the CV image or the input file name\"\n",
    "\t\n",
    "\tif isinstance( inp , six.string_types)  :\n",
    "\t\tinp = cv2.imread(inp )\n",
    "\n",
    "\tassert len(inp.shape) == 3 , \"Image should be h,w,3 \"\n",
    "\torininal_h = inp.shape[0]\n",
    "\torininal_w = inp.shape[1]\n",
    "\n",
    "\n",
    "\toutput_width = model.output_width\n",
    "\toutput_height  = model.output_height\n",
    "\tinput_width = model.input_width\n",
    "\tinput_height = model.input_height\n",
    "\tn_classes = model.n_classes\n",
    "\n",
    "\tx = get_image_arr( inp , input_width  , input_height , odering=IMAGE_ORDERING )\n",
    "\tpr = model.predict( np.array([x]) )[0]\n",
    "\tpr = pr.reshape(( output_height ,  output_width , n_classes ) ).argmax( axis=2 )\n",
    "\n",
    "\tseg_img = np.zeros( ( output_height , output_width , 3  ) )\n",
    "\tcolors = class_colors\n",
    "\n",
    "\tfor c in range(n_classes):\n",
    "\t\tseg_img[:,:,0] += ( (pr[:,: ] == c )*( colors[c][0] )).astype('uint8')\n",
    "\t\tseg_img[:,:,1] += ((pr[:,: ] == c )*( colors[c][1] )).astype('uint8')\n",
    "\t\tseg_img[:,:,2] += ((pr[:,: ] == c )*( colors[c][2] )).astype('uint8')\n",
    "\n",
    "\tseg_img = cv2.resize(seg_img  , (orininal_w , orininal_h ))\n",
    "\n",
    "\tif not out_fname is None:\n",
    "\t\tcv2.imwrite(  out_fname , seg_img )\n",
    "\n",
    "\n",
    "\treturn pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWA9DsArXx0i"
   },
   "outputs": [],
   "source": [
    "#models/vgg16.py\n",
    "if IMAGE_ORDERING == 'channels_first':\n",
    "\tpretrained_url = \"C:\\\\Users\\\\theza\\\\Documents\\\\Uni\\\\MIT\\\\2019\\\\TP\\\\Project\\\\Meal-Compliance-Project\\\\Image-segmentation\\\\models\\\\model_latest.h5\"\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "\tpretrained_url = \"C:\\\\Users\\\\theza\\\\Documents\\\\Uni\\\\MIT\\\\2019\\\\TP\\\\Project\\\\Meal-Compliance-Project\\\\Image-segmentation\\\\models\\\\model_latest.h5\"\n",
    "\n",
    "\n",
    "def get_vgg_encoder( input_height=224 ,  input_width=224 , pretrained='imagenet'):\n",
    "\n",
    "\tassert input_height%32 == 0\n",
    "\tassert input_width%32 == 0\n",
    "\n",
    "\tif IMAGE_ORDERING == 'channels_first':\n",
    "\t\timg_input = Input(shape=(3,input_height,input_width))\n",
    "\telif IMAGE_ORDERING == 'channels_last':\n",
    "\t\timg_input = Input(shape=(input_height,input_width , 3 ))\n",
    "\n",
    "\tx = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "\tx = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf1 = x\n",
    "\t# Block 2\n",
    "\tx = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf2 = x\n",
    "\n",
    "\t# Block 3\n",
    "\tx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf3 = x\n",
    "\n",
    "\t# Block 4\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf4 = x\n",
    "\n",
    "\t# Block 5\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf5 = x\n",
    "\n",
    "\t\n",
    "\tif pretrained == 'imagenet':\n",
    "\t\tVGG_Weights_path = keras.utils.get_file( pretrained_url.split(\"/\")[-1] , pretrained_url  )\n",
    "\t\tModel(  img_input , x  ).load_weights(VGG_Weights_path)\n",
    "\n",
    "\n",
    "\treturn img_input , [f1 , f2 , f3 , f4 , f5 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo2NwIg2aHfE"
   },
   "outputs": [],
   "source": [
    "def verify_segmentation_dataset( images_path , segs_path , n_classes ):\n",
    "\t\n",
    "\timg_seg_pairs = get_pairs_from_paths( images_path , segs_path )\n",
    "\t\n",
    "\tassert len(img_seg_pairs)>0 , \"Dataset looks empty or path is wrong \"\n",
    "\t\n",
    "\tfor im_fn , seg_fn in tqdm(img_seg_pairs) :\n",
    "\t\timg = cv2.imread( im_fn )\n",
    "\t\tseg = cv2.imread( seg_fn )\n",
    "\n",
    "\t\tassert ( img.shape[0]==seg.shape[0] and img.shape[1]==seg.shape[1] ) , \"The size of image and the annotation does not match or they are corrupt \"+ im_fn + \" \" + seg_fn\n",
    "\t\tassert ( np.max(seg[:,:,0]) < n_classes) , \"The pixel values of seg image should be from 0 to \"+str(n_classes-1) + \" . Found pixel value \"+str(np.max(seg[:,:,0]))\n",
    "\n",
    "\tprint(\"Dataset verified! \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-5ZI1uoaN2W"
   },
   "outputs": [],
   "source": [
    "def get_pairs_from_paths( images_path , segs_path ):\n",
    "\timages = glob.glob( os.path.join(images_path,\"*.jpg\")  ) + glob.glob( os.path.join(images_path,\"*.png\")  ) +  glob.glob( os.path.join(images_path,\"*.jpeg\")  )\n",
    "\tsegmentations  =  glob.glob( os.path.join(segs_path,\"*.png\")  ) \n",
    "\n",
    "\tsegmentations_d = dict( zip(segmentations,segmentations ))\n",
    "\n",
    "\tret = []\n",
    "\n",
    "\tfor im in images:\n",
    "\t\tseg_bnme = os.path.basename(im).replace(\".jpg\" , \".png\").replace(\".jpeg\" , \".png\")\n",
    "\t\tseg = os.path.join( segs_path , seg_bnme  )\n",
    "\t\tassert ( seg in segmentations_d ),  (im + \" is present in \"+images_path +\" but \"+seg_bnme+\" is not found in \"+segs_path + \" . Make sure annotation image are in .png\"  )\n",
    "\t\tret.append((im , seg) )\n",
    "\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUEjJI_hbTHu"
   },
   "outputs": [],
   "source": [
    "def get_image_arr( path , width , height , imgNorm=\"sub_mean\" , odering='channels_first' ):\n",
    "\n",
    "\n",
    "\tif type( path ) is np.ndarray:\n",
    "\t\timg = path\n",
    "\telse:\n",
    "\t\timg = cv2.imread(path, 1)\n",
    "\n",
    "\tif imgNorm == \"sub_and_divide\":\n",
    "\t\timg = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "\telif imgNorm == \"sub_mean\":\n",
    "\t\timg = cv2.resize(img, ( width , height ))\n",
    "\t\timg = img.astype(np.float32)\n",
    "\t\timg[:,:,0] -= 103.939\n",
    "\t\timg[:,:,1] -= 116.779\n",
    "\t\timg[:,:,2] -= 123.68\n",
    "\t\timg = img[ : , : , ::-1 ]\n",
    "\telif imgNorm == \"divide\":\n",
    "\t\timg = cv2.resize(img, ( width , height ))\n",
    "\t\timg = img.astype(np.float32)\n",
    "\t\timg = img/255.0\n",
    "\n",
    "\tif odering == 'channels_first':\n",
    "\t\timg = np.rollaxis(img, 2, 0)\n",
    "\treturn img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nlZk35wbbFN"
   },
   "outputs": [],
   "source": [
    "def get_segmentation_arr( path , nClasses ,  width , height , no_reshape=False ):\n",
    "\n",
    "\tseg_labels = np.zeros((  height , width  , nClasses ))\n",
    "\t\t\n",
    "\tif type( path ) is np.ndarray:\n",
    "\t\timg = path\n",
    "\telse:\n",
    "\t\timg = cv2.imread(path, 1)\n",
    "\n",
    "\timg = cv2.resize(img, ( width , height ) , interpolation=cv2.INTER_NEAREST )\n",
    "\timg = img[:, : , 0]\n",
    "\n",
    "\tfor c in range(nClasses):\n",
    "\t\tseg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "\n",
    "\n",
    "\t\n",
    "\tif no_reshape:\n",
    "\t\treturn seg_labels\n",
    "\n",
    "\tseg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
    "\treturn seg_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nZOGV_PYjjX"
   },
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "\tMERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "\tMERGE_AXIS = -1\n",
    "\n",
    "\n",
    "\n",
    "def unet_mini( n_classes , input_height=360, input_width=480   ):\n",
    "\n",
    "\tif IMAGE_ORDERING == 'channels_first':\n",
    "\t\timg_input = Input(shape=(3,input_height,input_width))\n",
    "\telif IMAGE_ORDERING == 'channels_last':\n",
    "\t\timg_input = Input(shape=(input_height,input_width , 3 ))\n",
    "\n",
    "\n",
    "\tconv1 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(img_input)\n",
    "\tconv1 = Dropout(0.2)(conv1)\n",
    "\tconv1 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(conv1)\n",
    "\tpool1 = MaxPooling2D((2, 2), data_format=IMAGE_ORDERING)(conv1)\n",
    "\t\n",
    "\tconv2 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(pool1)\n",
    "\tconv2 = Dropout(0.2)(conv2)\n",
    "\tconv2 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(conv2)\n",
    "\tpool2 = MaxPooling2D((2, 2), data_format=IMAGE_ORDERING)(conv2)\n",
    "\t\n",
    "\tconv3 = Conv2D(128, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(pool2)\n",
    "\tconv3 = Dropout(0.2)(conv3)\n",
    "\tconv3 = Conv2D(128, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(conv3)\n",
    "\n",
    "\tup1 = concatenate([UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(conv3), conv2], axis=MERGE_AXIS)\n",
    "\tconv4 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(up1)\n",
    "\tconv4 = Dropout(0.2)(conv4)\n",
    "\tconv4 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(conv4)\n",
    "\t\n",
    "\tup2 = concatenate([UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(conv4), conv1], axis=MERGE_AXIS)\n",
    "\tconv5 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(up2)\n",
    "\tconv5 = Dropout(0.2)(conv5)\n",
    "\tconv5 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING, activation='relu', padding='same')(conv5)\n",
    "\t\n",
    "\to = Conv2D( n_classes, (1, 1) , data_format=IMAGE_ORDERING ,padding='same')(conv5)\n",
    "\n",
    "\tmodel = get_segmentation_model(img_input , o )\n",
    "\tmodel.model_name = \"unet_mini\"\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def _unet( n_classes , encoder , l1_skip_conn=True,  input_height=416, input_width=608  ):\n",
    "\n",
    "\timg_input , levels = encoder( input_height=input_height ,  input_width=input_width )\n",
    "\t[f1 , f2 , f3 , f4 , f5 ] = levels \n",
    "\n",
    "\to = f4\n",
    "\n",
    "\to = ( ZeroPadding2D( (1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "\to = ( Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "\to = ( BatchNormalization())(o)\n",
    "\n",
    "\to = ( UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "\to = ( concatenate([ o ,f3],axis=MERGE_AXIS )  )\n",
    "\to = ( ZeroPadding2D( (1,1), data_format=IMAGE_ORDERING))(o)\n",
    "\to = ( Conv2D( 256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "\to = ( BatchNormalization())(o)\n",
    "\n",
    "\to = ( UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "\to = ( concatenate([o,f2],axis=MERGE_AXIS ) )\n",
    "\to = ( ZeroPadding2D((1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "\to = ( Conv2D( 128 , (3, 3), padding='valid' , data_format=IMAGE_ORDERING ) )(o)\n",
    "\to = ( BatchNormalization())(o)\n",
    "\n",
    "\to = ( UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "\t\n",
    "\tif l1_skip_conn:\n",
    "\t\to = ( concatenate([o,f1],axis=MERGE_AXIS ) )\n",
    "\n",
    "\to = ( ZeroPadding2D((1,1)  , data_format=IMAGE_ORDERING ))(o)\n",
    "\to = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format=IMAGE_ORDERING ))(o)\n",
    "\to = ( BatchNormalization())(o)\n",
    "\n",
    "\to =  Conv2D( n_classes , (3, 3) , padding='same', data_format=IMAGE_ORDERING )( o )\n",
    "\t\n",
    "\tmodel = get_segmentation_model(img_input , o )\n",
    "\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def unet(  n_classes ,  input_height=416, input_width=608 , encoder_level=3 ) : \n",
    "\t\n",
    "\tmodel =  _unet( n_classes , vanilla_encoder ,  input_height=input_height, input_width=input_width  )\n",
    "\tmodel.model_name = \"unet\"\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def vgg_unet( n_classes ,  input_height=416, input_width=608 , encoder_level=3):\n",
    "\n",
    "\tmodel =  _unet( n_classes , get_vgg_encoder ,  input_height=input_height, input_width=input_width  )\n",
    "\tmodel.model_name = \"vgg_unet\"\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "hnsKd3gDYPq6",
    "outputId": "c8b5a84a-e8a4-4885-c8e9-64e78ae08d71"
   },
   "outputs": [],
   "source": [
    "model = vgg_unet(n_classes=33 ,  input_height=1056, input_width=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "Sale9JVrZqSX",
    "outputId": "60460e8c-7cac-4d58-fd82-3d5f66647a20"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "huU6Jg3mZwzv",
    "outputId": "47e6421f-077c-4824-f8dd-294edfafd361"
   },
   "outputs": [],
   "source": [
    "import os # File/directory operations\n",
    "rootPath = os.path.abspath(os.path.join('content','drive','My Drive','example_dataset','XTrain'))\n",
    "!ls $rootPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iVoOmdjQc8M7",
    "outputId": "58949587-8299-46c4-e61c-b8251c2bfd05"
   },
   "outputs": [],
   "source": [
    "!ls '/content/drive/My Drive/example_dataset/XTrain'\n",
    "glob.glob( os.path.join(\"/content/drive/My Drive/example_dataset/XTrain\",\"*\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "colab_type": "code",
    "id": "Rx5EIa1yw8Yu",
    "outputId": "4d216b88-c18a-4ed5-cfc8-90d200fcc5fe"
   },
   "outputs": [],
   "source": [
    "model.train( \n",
    "    train_images =  \"/content/drive/My Drive/data/XTrain\",\n",
    "    train_annotations = \"/content/drive/My Drive/data/yTrain\",\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "YarRviQfm9_d",
    "outputId": "3a93271f-e3e3-4678-979c-9b837a8f511d"
   },
   "outputs": [],
   "source": [
    "class_colors = [  ( random.randint(0,255),random.randint(0,255),random.randint(0,255)   ) for _ in range(5000)  ]\n",
    "test_images =  \"/content/drive/My Drive/data/XTest\"\n",
    "test_annotations = \"/content/drive/My Drive/data/yTest\"\n",
    "testIm = glob.glob( os.path.join(test_images,\"*\")  ) \n",
    "testAn = glob.glob( os.path.join(test_annotations,\"*\")  )\n",
    "\n",
    "train_images =  \"/content/drive/My Drive/data/XTrain\"\n",
    "train_annotations = \"/content/drive/My Drive/data/yTrain\"\n",
    "trainIm = glob.glob( os.path.join(train_images,\"*\")  ) \n",
    "trainAn = glob.glob( os.path.join(train_annotations,\"*\")  )\n",
    "\n",
    "\n",
    "testIm.sort()\n",
    "testAn.sort()\n",
    "trainIm.sort()\n",
    "trainAn.sort()\n",
    "print(testIm)\n",
    "print(testAn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRT1uxPOzUC9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from skimage.transform import resize # Resize images\n",
    "\n",
    "def res(annot, heightNew, width):\n",
    "  annotNew = resize(annot, (heightNew, width),mode='edge', anti_aliasing=False,\n",
    "                             anti_aliasing_sigma=None,preserve_range=True,\n",
    "                             order=0).astype(int)\n",
    "  df = (pd.DataFrame(annotNew))\n",
    "  _, b = pd.factorize(df.values.T.reshape(-1, ))  \n",
    "\n",
    "  # print(df.apply(lambda x: pd.Categorical(x, b).codes).values.shape)\n",
    "  annotNewOut = df.apply(lambda x: pd.Categorical(x, b).codes).values\n",
    "  return annotNewOut\n",
    "\n",
    "def evaluate( model=None , inp_images=None , annotations=None):\n",
    "  ious = []\n",
    "  for im, an in zip(inp_images,annotations):\n",
    "    img_true =  res(cv2.cvtColor(cv2.imread(an), cv2.COLOR_BGR2GRAY),528,800)\n",
    "    img_pred = predict(model,im)\n",
    "    img_true=np.array(img_true).ravel()\n",
    "    img_pred=np.array(img_pred).ravel()\n",
    "    iou = jaccard_score(img_true, img_pred,average='micro')\n",
    "    ious.append(iou)\n",
    "  return np.mean(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "89F8Q6WdQWdk",
    "outputId": "6c5af3fc-d5f4-4fca-a48b-ec6736ab0f9f"
   },
   "outputs": [],
   "source": [
    "evaluate(model,trainIm,trainAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m99FuGyazUwl",
    "outputId": "4f457fe4-f0d2-4323-e80d-a29f16c9301e"
   },
   "outputs": [],
   "source": [
    "evaluate(model,testIm,testAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "MUF9EoYa0FBC",
    "outputId": "316492f1-3d45-431d-bb0d-58ed08324f1e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "img_true =  res(cv2.cvtColor(cv2.imread(testAn[0]), cv2.COLOR_BGR2GRAY),528,800)\n",
    "img_pred = predict(model,testIm[0])\n",
    "print(img_true.shape)\n",
    "print(img_pred.shape)\n",
    "img_true=np.array(img_true).ravel()\n",
    "img_pred=np.array(img_pred).ravel()\n",
    "print(len(img_true))\n",
    "print(len(img_pred))\n",
    "iou = jaccard_similarity_score(img_true, img_pred)\n",
    "\n",
    "iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSpWJYpeeQOM"
   },
   "outputs": [],
   "source": [
    "out = model.predict_segmentation(\n",
    "    inp=testIm[0],\n",
    "    out_fname=\"1cout.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7h1Hy6aPaxP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "03ttUKUKnEvk",
    "outputId": "aa9cb11e-c8eb-4020-a4ea-6f464cf17706"
   },
   "outputs": [],
   "source": [
    "pd.Series(out.view().ravel('K')).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3AvSGmNnTfp"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Hj_rGl0F5Ze6",
    "outputId": "24691cb5-07cf-47c5-997c-b4d1416153a8"
   },
   "outputs": [],
   "source": [
    "iou"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "image-segmentation-tests.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
